{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "# MNIST Image Classification with TensorFlow\n",
    "\n",
    "This notebook demonstrates how to implement a simple linear image models on MNIST using tf.keras.\n",
    "<hr/>\n",
    "This <a href=\"mnist_models.ipynb\">companion notebook</a> extends the basic harness of this notebook to a variety of models including DNN, CNN, dropout, pooling etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "!sudo chown -R jupyter:jupyter /home/jupyter/training-data-analyst"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.3.1\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import shutil\n",
    "import os\n",
    "import tensorflow.compat.v1 as tf\n",
    "tf.disable_v2_behavior()\n",
    "print(tf.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Exploring the data\n",
    "\n",
    "Let's download MNIST data and examine the shape. We will need these numbers ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "HEIGHT = 28\n",
    "WIDTH = 28\n",
    "NCLASSES = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/train-labels-idx1-ubyte.gz\n",
      "32768/29515 [=================================] - 0s 0us/step\n",
      "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/train-images-idx3-ubyte.gz\n",
      "26427392/26421880 [==============================] - 0s 0us/step\n",
      "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/t10k-labels-idx1-ubyte.gz\n",
      "8192/5148 [===============================================] - 0s 0us/step\n",
      "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/t10k-images-idx3-ubyte.gz\n",
      "4423680/4422102 [==============================] - 0s 0us/step\n",
      "x_train.shape = (60000, 28, 28)\n",
      "y_train.shape = (60000, 10)\n",
      "x_test.shape = (10000, 28, 28)\n",
      "y_test.shape = (10000, 10)\n"
     ]
    }
   ],
   "source": [
    "# Get mnist data\n",
    "mnist = tf.keras.datasets.fashion_mnist\n",
    "\n",
    "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
    "\n",
    "# Scale our features between 0 and 1\n",
    "x_train, x_test = x_train / 255.0, x_test / 255.0 \n",
    "\n",
    "# Convert labels to categorical one-hot encoding\n",
    "y_train = tf.keras.utils.to_categorical(y = y_train, num_classes = NCLASSES)\n",
    "y_test = tf.keras.utils.to_categorical(y = y_test, num_classes = NCLASSES)\n",
    "\n",
    "print(\"x_train.shape = {}\".format(x_train.shape))\n",
    "print(\"y_train.shape = {}\".format(y_train.shape))\n",
    "print(\"x_test.shape = {}\".format(x_test.shape))\n",
    "print(\"y_test.shape = {}\".format(y_test.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "IMGNO = 11\n",
    "plt.imshow(x_test[IMGNO].reshape(HEIGHT, WIDTH), cmap ='inferno');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Define the model.\n",
    "Let's start with a very simple linear classifier. All our models will have this basic interface -- they will take an image and return probabilities."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "# Build Keras Model Using Keras Sequential API\n",
    "def linear_model():\n",
    "    model = tf.keras.models.Sequential()\n",
    "    model.add(tf.keras.layers.InputLayer(input_shape = [HEIGHT, WIDTH], name = \"image\"))\n",
    "    model.add(tf.keras.layers.Flatten())\n",
    "    model.add(tf.keras.layers.Dense(units = 20, activation = tf.nn.relu, name = \"dense_1\"))\n",
    "    model.add(tf.keras.layers.Dense(units = 20, activation = tf.nn.relu, name = \"dense_2\"))\n",
    "    model.add(tf.keras.layers.Dense(units = 15, activation = tf.nn.relu, name = \"dense_3\"))\n",
    "    model.add(tf.keras.layers.Dense(units = NCLASSES, activation = tf.nn.softmax, name = \"probabilities\"))\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Write Input Functions\n",
    "\n",
    "As usual, we need to specify input functions for training, evaluation, and predicition."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "# Create training input function\n",
    "train_input_fn = tf.estimator.inputs.numpy_input_fn(\n",
    "    x = {\"image\": x_train},\n",
    "    y = y_train,\n",
    "    batch_size = 100,\n",
    "    num_epochs = None,\n",
    "    shuffle = True,\n",
    "    queue_capacity = 5000\n",
    "  )\n",
    "\n",
    "# Create evaluation input function\n",
    "eval_input_fn = tf.estimator.inputs.numpy_input_fn(\n",
    "    x = {\"image\": x_test},\n",
    "    y = y_test,\n",
    "    batch_size = 100,\n",
    "    num_epochs = 1,\n",
    "    shuffle = False,\n",
    "    queue_capacity = 5000\n",
    "  )\n",
    "\n",
    "# Create serving input function for inference\n",
    "def serving_input_fn():\n",
    "    placeholders = {\"image\": tf.placeholder(dtype = tf.float32, shape = [None, HEIGHT, WIDTH])}\n",
    "    features = placeholders # as-is\n",
    "    return tf.estimator.export.ServingInputReceiver(features = features, receiver_tensors = placeholders)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Create train_and_evaluate function"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    " tf.estimator.train_and_evaluate does distributed training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "def train_and_evaluate(output_dir, hparams):\n",
    "    # Build Keras model\n",
    "    model = linear_model()\n",
    "        \n",
    "    # Compile Keras model with optimizer, loss function, and eval metrics\n",
    "    model.compile(\n",
    "        optimizer = \"adam\",\n",
    "        loss = \"categorical_crossentropy\",\n",
    "        metrics = [\"accuracy\"])\n",
    "        \n",
    "    # Convert Keras model to an Estimator\n",
    "    estimator = tf.keras.estimator.model_to_estimator(\n",
    "        keras_model = model, \n",
    "        model_dir = output_dir)\n",
    "\n",
    "    # Set estimator's train_spec to use train_input_fn and train for so many steps\n",
    "    train_spec = tf.estimator.TrainSpec(\n",
    "        input_fn = train_input_fn,\n",
    "        max_steps = hparams[\"train_steps\"])\n",
    "\n",
    "    # Create exporter that uses serving_input_fn to create saved_model for serving\n",
    "    exporter = tf.estimator.LatestExporter(\n",
    "        name = \"exporter\", \n",
    "        serving_input_receiver_fn = serving_input_fn)\n",
    "\n",
    "    # Set estimator's eval_spec to use eval_input_fn and export saved_model\n",
    "    eval_spec = tf.estimator.EvalSpec(\n",
    "        input_fn = eval_input_fn,\n",
    "        steps = None,\n",
    "        exporters = exporter)\n",
    "\n",
    "    # Run train_and_evaluate loop\n",
    "    tf.estimator.train_and_evaluate(\n",
    "        estimator = estimator, \n",
    "        train_spec = train_spec, \n",
    "        eval_spec = eval_spec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "This is the main() function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Using default config.\n",
      "INFO:tensorflow:Using the Keras model provided.\n",
      "INFO:tensorflow:Using config: {'_model_dir': 'fashion/learned', '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': allow_soft_placement: true\n",
      "graph_options {\n",
      "  rewrite_options {\n",
      "    meta_optimizer_iterations: ONE\n",
      "  }\n",
      "}\n",
      ", '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 100, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_experimental_max_worker_delay_secs': None, '_session_creation_timeout_secs': 7200, '_service': None, '_cluster_spec': ClusterSpec({}), '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}\n",
      "INFO:tensorflow:Not using Distribute Coordinator.\n",
      "INFO:tensorflow:Running training and evaluation locally (non-distributed).\n",
      "INFO:tensorflow:Start train and evaluate loop. The evaluate will happen after every checkpoint. Checkpoint frequency is determined based on RunConfig arguments: save_checkpoints_steps None or save_checkpoints_secs 600.\n",
      "INFO:tensorflow:Calling model_fn.\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Warm-starting with WarmStartSettings: WarmStartSettings(ckpt_to_initialize_from='fashion/learned/keras/keras_model.ckpt', vars_to_warm_start='.*', var_name_to_vocab_info={}, var_name_to_prev_var_name={})\n",
      "INFO:tensorflow:Warm-starting from: fashion/learned/keras/keras_model.ckpt\n",
      "INFO:tensorflow:Warm-starting variables only in TRAINABLE_VARIABLES.\n",
      "INFO:tensorflow:Warm-started 8 variables.\n",
      "INFO:tensorflow:Create CheckpointSaverHook.\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Calling checkpoint listeners before saving checkpoint 0...\n",
      "INFO:tensorflow:Saving checkpoints for 0 into fashion/learned/model.ckpt.\n",
      "INFO:tensorflow:Calling checkpoint listeners after saving checkpoint 0...\n",
      "INFO:tensorflow:loss = 2.3468213, step = 1\n",
      "INFO:tensorflow:global_step/sec: 78.599\n",
      "INFO:tensorflow:loss = 0.83660895, step = 101 (1.274 sec)\n",
      "INFO:tensorflow:global_step/sec: 134.001\n",
      "INFO:tensorflow:loss = 0.63879895, step = 201 (0.750 sec)\n",
      "INFO:tensorflow:global_step/sec: 109.344\n",
      "INFO:tensorflow:loss = 0.4747986, step = 301 (0.911 sec)\n",
      "INFO:tensorflow:global_step/sec: 94.2415\n",
      "INFO:tensorflow:loss = 0.42954934, step = 401 (1.061 sec)\n",
      "INFO:tensorflow:global_step/sec: 89.9256\n",
      "INFO:tensorflow:loss = 0.411496, step = 501 (1.112 sec)\n",
      "INFO:tensorflow:global_step/sec: 122.626\n",
      "INFO:tensorflow:loss = 0.55399954, step = 601 (0.821 sec)\n",
      "INFO:tensorflow:global_step/sec: 141.479\n",
      "INFO:tensorflow:loss = 0.5458425, step = 701 (0.708 sec)\n",
      "INFO:tensorflow:global_step/sec: 124.739\n",
      "INFO:tensorflow:loss = 0.45797026, step = 801 (0.801 sec)\n",
      "INFO:tensorflow:global_step/sec: 117.082\n",
      "INFO:tensorflow:loss = 0.5107274, step = 901 (0.853 sec)\n",
      "INFO:tensorflow:global_step/sec: 100.179\n",
      "INFO:tensorflow:loss = 0.4473758, step = 1001 (0.998 sec)\n",
      "INFO:tensorflow:global_step/sec: 105.792\n",
      "INFO:tensorflow:loss = 0.5639393, step = 1101 (0.947 sec)\n",
      "INFO:tensorflow:global_step/sec: 116.82\n",
      "INFO:tensorflow:loss = 0.33033222, step = 1201 (0.854 sec)\n",
      "INFO:tensorflow:global_step/sec: 124.486\n",
      "INFO:tensorflow:loss = 0.42590037, step = 1301 (0.798 sec)\n",
      "INFO:tensorflow:global_step/sec: 110.701\n",
      "INFO:tensorflow:loss = 0.44357595, step = 1401 (0.904 sec)\n",
      "INFO:tensorflow:global_step/sec: 113.682\n",
      "INFO:tensorflow:loss = 0.33050287, step = 1501 (0.883 sec)\n",
      "INFO:tensorflow:global_step/sec: 129.954\n",
      "INFO:tensorflow:loss = 0.5257963, step = 1601 (0.771 sec)\n",
      "INFO:tensorflow:global_step/sec: 129.842\n",
      "INFO:tensorflow:loss = 0.49197719, step = 1701 (0.769 sec)\n",
      "INFO:tensorflow:global_step/sec: 137.052\n",
      "INFO:tensorflow:loss = 0.5252204, step = 1801 (0.731 sec)\n",
      "INFO:tensorflow:global_step/sec: 134.627\n",
      "INFO:tensorflow:loss = 0.41345474, step = 1901 (0.737 sec)\n",
      "INFO:tensorflow:global_step/sec: 129.89\n",
      "INFO:tensorflow:loss = 0.47703752, step = 2001 (0.774 sec)\n",
      "INFO:tensorflow:global_step/sec: 142.442\n",
      "INFO:tensorflow:loss = 0.37058982, step = 2101 (0.698 sec)\n",
      "INFO:tensorflow:global_step/sec: 141.058\n",
      "INFO:tensorflow:loss = 0.42753723, step = 2201 (0.713 sec)\n",
      "INFO:tensorflow:global_step/sec: 161.623\n",
      "INFO:tensorflow:loss = 0.34318405, step = 2301 (0.642 sec)\n",
      "INFO:tensorflow:global_step/sec: 95.9257\n",
      "INFO:tensorflow:loss = 0.44140273, step = 2401 (1.017 sec)\n",
      "INFO:tensorflow:global_step/sec: 148.625\n",
      "INFO:tensorflow:loss = 0.38021815, step = 2501 (0.673 sec)\n",
      "INFO:tensorflow:global_step/sec: 108.491\n",
      "INFO:tensorflow:loss = 0.39499435, step = 2601 (0.927 sec)\n",
      "INFO:tensorflow:global_step/sec: 91.5484\n",
      "INFO:tensorflow:loss = 0.37086532, step = 2701 (1.090 sec)\n",
      "INFO:tensorflow:global_step/sec: 89.4685\n",
      "INFO:tensorflow:loss = 0.39088959, step = 2801 (1.119 sec)\n",
      "INFO:tensorflow:global_step/sec: 73.3044\n",
      "INFO:tensorflow:loss = 0.36664894, step = 2901 (1.363 sec)\n",
      "INFO:tensorflow:Calling checkpoint listeners before saving checkpoint 3000...\n",
      "INFO:tensorflow:Saving checkpoints for 3000 into fashion/learned/model.ckpt.\n",
      "INFO:tensorflow:Calling checkpoint listeners after saving checkpoint 3000...\n",
      "INFO:tensorflow:Calling model_fn.\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Starting evaluation at 2020-11-02T14:24:48Z\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from fashion/learned/model.ckpt-3000\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Inference Time : 1.08130s\n",
      "INFO:tensorflow:Finished evaluation at 2020-11-02-14:24:49\n",
      "INFO:tensorflow:Saving dict for global step 3000: acc = 0.848, global_step = 3000, loss = 0.4340281\n",
      "INFO:tensorflow:Saving 'checkpoint_path' summary for global step 3000: fashion/learned/model.ckpt-3000\n",
      "INFO:tensorflow:Calling model_fn.\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Signatures INCLUDED in export for Classify: None\n",
      "INFO:tensorflow:Signatures INCLUDED in export for Regress: None\n",
      "INFO:tensorflow:Signatures INCLUDED in export for Predict: ['serving_default']\n",
      "INFO:tensorflow:Signatures INCLUDED in export for Train: None\n",
      "INFO:tensorflow:Signatures INCLUDED in export for Eval: None\n",
      "INFO:tensorflow:Restoring parameters from fashion/learned/model.ckpt-3000\n",
      "INFO:tensorflow:Assets added to graph.\n",
      "INFO:tensorflow:No assets to write.\n",
      "INFO:tensorflow:SavedModel written to: fashion/learned/export/exporter/temp-1604327089/saved_model.pb\n",
      "INFO:tensorflow:Loss for final step: 0.4079879.\n"
     ]
    }
   ],
   "source": [
    "OUTDIR = \"fashion/learned\"\n",
    "shutil.rmtree(OUTDIR, ignore_errors = True) # start fresh each time\n",
    "\n",
    "hparams = {\"train_steps\": 3000, \"learning_rate\": 0.001}\n",
    "hist = train_and_evaluate(OUTDIR, hparams)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'NoneType'>\n"
     ]
    }
   ],
   "source": [
    "print(type(hist))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I got:\n",
    "\n",
    "`Saving dict for global step 1000: categorical_accuracy = 0.9112, global_step = 1000, loss = 0.32516304`\n",
    "\n",
    "In other words, we achieved 91.12% accuracy with the simple linear model!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "<pre>\n",
    "# Copyright 2020 Google Inc. All Rights Reserved.\n",
    "#\n",
    "# Licensed under the Apache License, Version 2.0 (the \"License\");\n",
    "# you may not use this file except in compliance with the License.\n",
    "# You may obtain a copy of the License at\n",
    "#\n",
    "#      http://www.apache.org/licenses/LICENSE-2.0\n",
    "#\n",
    "# Unless required by applicable law or agreed to in writing, software\n",
    "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
    "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
    "# See the License for the specific language governing permissions and\n",
    "# limitations under the License.\n",
    "</pre>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "environment": {
   "name": "tf2-2-3-gpu.2-3.m58",
   "type": "gcloud",
   "uri": "gcr.io/deeplearning-platform-release/tf2-2-3-gpu.2-3:m58"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
