{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "TFLite_Week2_Exercise4_foods101_mobileNetv2224_transfer_learning.ipynb",
      "provenance": [],
      "private_outputs": true,
      "collapsed_sections": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.4"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Za8-Nr5k11fh"
      },
      "source": [
        "##### Copyright 2018 The TensorFlow Authors."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "cellView": "form",
        "id": "Eq10uEbw0E4l"
      },
      "source": [
        "#@title Licensed under the Apache License, Version 2.0 (the \"License\");\n",
        "# you may not use this file except in compliance with the License.\n",
        "# You may obtain a copy of the License at\n",
        "#\n",
        "# https://www.apache.org/licenses/LICENSE-2.0\n",
        "#\n",
        "# Unless required by applicable law or agreed to in writing, software\n",
        "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
        "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
        "# See the License for the specific language governing permissions and\n",
        "# limitations under the License."
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oYM61xrTsP5d"
      },
      "source": [
        "# FOOD1 with TensorFlow Hub - TFLite"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xWFpUd1yy3gt"
      },
      "source": [
        "<table class=\"tfo-notebook-buttons\" align=\"left\">\n",
        "  <td>\n",
        "    <a target=\"_blank\" href=\"https://colab.research.google.com/github/lmoroney/dlaicourse/blob/master/TensorFlow%20Deployment/Course%202%20-%20TensorFlow%20Lite/Week%202/Exercise/TFLite_Week2_Exercise_Answer.ipynb\">\n",
        "    <img src=\"https://www.tensorflow.org/images/colab_logo_32px.png\" />\n",
        "    Run in Google Colab</a>\n",
        "  </td>\n",
        "  <td>\n",
        "    <a target=\"_blank\" href=\"https://github.com/lmoroney/dlaicourse/blob/master/TensorFlow%20Deployment/Course%202%20-%20TensorFlow%20Lite/Week%202/Exercise/TFLite_Week2_Exercise_Answer.ipynb\">\n",
        "    <img src=\"https://www.tensorflow.org/images/GitHub-Mark-32px.png\" />\n",
        "    View source on GitHub</a>\n",
        "  </td>\n",
        "</table>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bL54LWCHt5q5"
      },
      "source": [
        "## Setup"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "110fGB18UNJn"
      },
      "source": [
        "try:\n",
        "    %tensorflow_version 2.x\n",
        "except:\n",
        "    pass\n",
        "# Load the TensorBoard notebook extension.\n",
        "%load_ext tensorboard"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dlauq-4FWGZM"
      },
      "source": [
        "from datetime import datetime\n",
        "import io\n",
        "import itertools\n",
        "from packaging import version\n",
        "from six.moves import range\n",
        "import sklearn.metrics\n",
        "\n",
        "\n",
        "import numpy as np\n",
        "import matplotlib.pylab as plt\n",
        "\n",
        "import tensorflow as tf\n",
        "import tensorflow_hub as hub\n",
        "\n",
        "from tqdm import tqdm\n",
        "\n",
        "print(\"\\u2022 Using TensorFlow Version:\", tf.__version__)\n",
        "print(\"\\u2022 Using TensorFlow Hub Version: \", hub.__version__)\n",
        "print('\\u2022 GPU Device Found.' if tf.test.is_gpu_available() else '\\u2022 GPU Device Not Found. Running on CPU')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mmaHHH7Pvmth"
      },
      "source": [
        "## Select the Hub/TF2 Module to Use\n",
        "\n",
        "Hub modules for TF 1.x won't work here, please use one of the selections provided."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FlsEcKVeuCnf"
      },
      "source": [
        "module_selection = (\"mobilenet_v2\", 224, 1280) #@param [\"(\\\"mobilenet_v2\\\", 224, 1280)\", \"(\\\"inception_v3\\\", 299, 2048)\"] {type:\"raw\", allow-input: true}\n",
        "handle_base, pixels, FV_SIZE = module_selection\n",
        "MODULE_HANDLE =\"https://tfhub.dev/google/tf2-preview/{}/feature_vector/4\".format(handle_base)\n",
        "IMAGE_SIZE = (pixels, pixels)\n",
        "print(\"Using {} with input size {} and output dimension {}\".format(MODULE_HANDLE, IMAGE_SIZE, FV_SIZE))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sYUsgwCBv87A"
      },
      "source": [
        "## Data Preprocessing"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8nqVX3KYwGPh"
      },
      "source": [
        "Use [TensorFlow Datasets](http://tensorflow.org/datasets) to load the cats and dogs dataset.\n",
        "\n",
        "This `tfds` package is the easiest way to load pre-defined data. If you have your own data, and are interested in importing using it with TensorFlow see [loading image data](../load_data/images.ipynb)\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jGvpkDj4wBup"
      },
      "source": [
        "import tensorflow_datasets as tfds\n",
        "#tfds.disable_progress_bar()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YkF4Boe5wN7N"
      },
      "source": [
        "The `tfds.load` method downloads and caches the data, and returns a `tf.data.Dataset` object. These objects provide powerful, efficient methods for manipulating data and piping it into your model.\n",
        "\n",
        "Since `\"cats_vs_dog\"` doesn't define standard splits, use the subsplit feature to divide it into (train, validation, test) with 80%, 10%, 10% of the data respectively."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SQ9xK9F2wGD8"
      },
      "source": [
        "import urllib3\n",
        "urllib3.disable_warnings(urllib3.exceptions.InsecureRequestWarning)\n",
        "#splits = tfds.Split.(weighted=(80, 10, 10))\n",
        "\n",
        "splits, info = tfds.load('food101', with_info=True, as_supervised=True, split = ['train' ,'validation[:50%]' ,'validation[50%:]'])\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yySdIHg-i_xh"
      },
      "source": [
        "(train_examples, validation_examples, test_examples) = splits"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XoeKVvbTQXvJ"
      },
      "source": [
        "num_examples = info.splits['train'].num_examples\n",
        "num_classes = info.features['label'].num_classes\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "print(num_classes)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2EknoZnqoInk"
      },
      "source": [
        "class_names = np.array(info.features['label'].names)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zM3dz3V4pLzI"
      },
      "source": [
        "print(class_names)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w4MgJbv8s4o6"
      },
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import cv2\n",
        "\n",
        "%matplotlib inline\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bBDNqv2EKoeH"
      },
      "source": [
        "get_label_name = info.features['label'].int2str\n",
        "#for i in range(num_classes):\n",
        " #print(get_label_name(i))\n",
        "\n",
        "f, (ax1, ax2) = plt.subplots(1, 2, figsize=(20,10))\n",
        "for image, label in train_examples.take(4):\n",
        "  #print(image.shape)\n",
        "  gray = cv2.cvtColor(image.numpy(), cv2.COLOR_RGB2GRAY)\n",
        "  # Try Canny using \"wide\" and \"tight\" thresholds\n",
        "  wide = cv2.Canny(gray, 30, 100)\n",
        "  tight = cv2.Canny(gray, 200, 240)\n",
        " \n",
        "  ax1.set_title('wide')\n",
        "  ax1.imshow(wide, cmap='gray')\n",
        "\n",
        "  ax2.set_title('tight')\n",
        "  ax2.imshow(tight, cmap='gray')\n",
        "    \n",
        "# Display the images\n",
        "\n",
        "\n",
        "  plt.figure()\n",
        "  plt.imshow(image)\n",
        "  print(label)\n",
        "  plt.title(get_label_name(label))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "recn8GsLquYe"
      },
      "source": [
        "train_label = [ label for image, label in train_examples]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tV-yf8YePHwG"
      },
      "source": [
        "\n",
        "#print(train_images)\n",
        "\n",
        "# Clear out prior logging data.\n",
        "!rm -rf logs/plots\n",
        "\n",
        "logdir = \"logs/plots/\" + datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
        "file_writer = tf.summary.create_file_writer(logdir)\n",
        "\n",
        "def plot_to_image(figure):\n",
        "  \"\"\"Converts the matplotlib plot specified by 'figure' to a PNG image and\n",
        "  returns it. The supplied figure is closed and inaccessible after this call.\"\"\"\n",
        "  # Save the plot to a PNG in memory.\n",
        "  buf = io.BytesIO()\n",
        "  plt.savefig(buf, format='png')\n",
        "  # Closing the figure prevents it from being displayed directly inside\n",
        "  # the notebook.\n",
        "  plt.close(figure)\n",
        "  buf.seek(0)\n",
        "  # Convert PNG buffer to TF image\n",
        "  image = tf.image.decode_png(buf.getvalue(), channels=4)\n",
        "  # Add the batch dimension\n",
        "  image = tf.expand_dims(image, 0)\n",
        "  return image\n",
        "\n",
        "def image_grid():\n",
        "  \"\"\"Return a 5x5 grid of the MNIST images as a matplotlib figure.\"\"\"\n",
        "  # Create a figure to contain the plot.\n",
        "  figure = plt.figure(figsize=(20,20))\n",
        "  for i in range(25):\n",
        "    # Start next subplot.\n",
        "    plt.subplot(5, 5, i + 1, title=class_names[train_label[i]])\n",
        "    plt.xticks([])\n",
        "    plt.yticks([])\n",
        "    plt.grid(False)\n",
        "    plt.imshow([image for image, label in train_examples.take(28)][i] )\n",
        "  \n",
        "  return figure\n",
        "\n",
        "# Prepare the plot\n",
        "figure = image_grid()\n",
        "# Convert to image and log\n",
        "with file_writer.as_default():\n",
        "  tf.summary.image(\"Training data\", plot_to_image(figure), step=0)\n",
        "\n",
        "#"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JK0ZrabdIb3v"
      },
      "source": [
        "%tensorboard --logdir logs/plots"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pmXQYXNWwf19"
      },
      "source": [
        "### Format the Data\n",
        "\n",
        "Use the `tf.image` module to format the images for the task.\n",
        "\n",
        "Resize the images to a fixes input size, and rescale the input channels"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y7UyXblSwkUS"
      },
      "source": [
        "def format_image(image, label):\n",
        "    image = tf.cast(image, tf.float32)\n",
        "    #image = tf.image.grayscale_to_rgb(image)\n",
        "    image = tf.image.resize(image, IMAGE_SIZE) #/ 255.0\n",
        "    #print(image.get_shape)\n",
        "    return  image, label"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1nrDR8CnwrVk"
      },
      "source": [
        "Now shuffle and batch the data\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zAEUG7vawxLm"
      },
      "source": [
        "BATCH_SIZE =  128#@param {type:\"integer\"}"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fHEC9mbswxvM"
      },
      "source": [
        "train_batches = train_examples.shuffle(1000).map(format_image).batch(BATCH_SIZE).prefetch(1)\n",
        "\n",
        "\n",
        "validation_batches = validation_examples.map(format_image).batch(BATCH_SIZE).prefetch(1)\n",
        "\n",
        "cm_validation_batches = validation_examples.map(format_image).batch(2160).prefetch(1)\n",
        "\n",
        "\n",
        "test_batches = test_examples.batch(1).map(format_image)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZHCjZpT-W6O4"
      },
      "source": [
        "print(0.90*2400)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ghQhZjgEw1cK"
      },
      "source": [
        "Inspect a batch"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gz0xsMCjwx54"
      },
      "source": [
        "for image_batch, label_batch in train_batches.take(1):\n",
        "    pass\n",
        "\n",
        "image_batch.shape"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j9EIdubhyQVe"
      },
      "source": [
        "\n",
        "a,  = cm_validation_batches.take(1)\n",
        "im , l = a[0], a[1]\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "print(im.shape)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Hfl3ABGUUbfc"
      },
      "source": [
        "from matplotlib.colors import Normalize\n",
        "import matplotlib.cm  as cm\n",
        "\n",
        "\n",
        "def class_distribution(train_examples , validation_examples , test_examples):\n",
        "        train_label_plot = [ label for image, label in train_examples]\n",
        "        valid_label_plot = [ label for image, label in validation_examples]\n",
        "        test_label_plot = [ label for image, label in test_examples]\n",
        "        unique, counts = np.unique(train_label_plot, return_counts=True)\n",
        "        #print(unique)\n",
        "\n",
        "        my_cmap = cm.get_cmap('jet')\n",
        "        plt.figure(figsize=(20,70))\n",
        "        # Get normalize function (takes data in range [vmin, vmax] -> [0, 1])\n",
        "        my_norm = Normalize(vmin=0, vmax=196)\n",
        "        plt.barh(unique, counts ,color=my_cmap(my_norm(unique)))\n",
        "\n",
        "        plt.yticks(unique, class_names)\n",
        "        plt.title('Class Frequency')\n",
        "        plt.xlabel('Class')\n",
        "        plt.ylabel('Frequency')\n",
        "        plt.show()\n",
        "\n",
        "        fig = plt.gcf\n",
        "\n",
        "        return fig\n",
        "\n",
        "class_distribution(train_examples , validation_examples , test_examples)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rb8eERRGgbmS"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FS_gVStowW3G"
      },
      "source": [
        "## Defining the Model\n",
        "\n",
        "All it takes is to put a linear classifier on top of the `feature_extractor_layer` with the Hub module.\n",
        "\n",
        "For speed, we start out with a non-trainable `feature_extractor_layer`, but you can also enable fine-tuning for greater accuracy."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RaJW3XrPyFiF"
      },
      "source": [
        "do_fine_tuning = True #@param {type:\"boolean\"}"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J1nwH2HhKS9W"
      },
      "source": [
        "feature_extractor = hub.KerasLayer(MODULE_HANDLE,\n",
        "                                   input_shape=IMAGE_SIZE + (3,), \n",
        "                                   output_shape=[FV_SIZE],\n",
        "                                   trainable=do_fine_tuning)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SFqM1WV5KS9b"
      },
      "source": [
        "print(\"Building model with\", MODULE_HANDLE)\n",
        "\n",
        "model = tf.keras.Sequential([\n",
        "        feature_extractor,\n",
        "        #tf.keras.layers.Dense(1280, activation='relu'),\n",
        "        tf.keras.layers.Dense(num_classes, activation='softmax')\n",
        "])\n",
        "\n",
        "model.summary()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8_bUY_IYKS9h"
      },
      "source": [
        "#@title (Optional) Unfreeze some layers\n",
        "NUM_LAYERS = 3 #@param {type:\"slider\", min:1, max:50, step:1}\n",
        "      \n",
        "if do_fine_tuning:\n",
        "    feature_extractor.trainable = False\n",
        "    \n",
        "    for layer in model.layers[-NUM_LAYERS:]:\n",
        "        layer.trainable = True\n",
        "\n",
        "else:\n",
        "    feature_extractor.trainable = False"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V6dzU4mO7VS3"
      },
      "source": [
        "model.summary()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "u2e5WupIw2N2"
      },
      "source": [
        "## Training the Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9f3yBUvkd_VJ"
      },
      "source": [
        "if do_fine_tuning:\n",
        "    model.compile(optimizer=tf.keras.optimizers.Adam(lr=0.001),\n",
        "                  loss=tf.keras.losses.SparseCategoricalCrossentropy(),\n",
        "                  metrics=['accuracy'])\n",
        "else:\n",
        "    model.compile(optimizer='adam',\n",
        "                  loss='sparse_categorical_crossentropy',\n",
        "                  metrics=['accuracy'])\n",
        "reduce_lr = tf.keras.callbacks.ReduceLROnPlateau(monitor='val_loss', factor=0.2, patience=5, min_lr=0.0001)\n",
        "early_stop_callback = tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=7 , mode = 'min')\n",
        "model.summary()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LI2NzIQBYRIF"
      },
      "source": [
        "!rm -rf logs/image\n",
        "\n",
        "logdir = \"logs/image/\" + datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
        "# Define the basic TensorBoard callback.\n",
        "tensorboard_callback = tf.keras.callbacks.TensorBoard(log_dir=logdir)\n",
        "file_writer_cm = tf.summary.create_file_writer(logdir + '/cm')\n",
        "file_writer_roc = tf.summary.create_file_writer(logdir + '/roc')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Qz7FobExgKxQ"
      },
      "source": [
        "def plot_confusion_matrix(cm, class_names):\n",
        "  \"\"\"\n",
        "  Returns a matplotlib figure containing the plotted confusion matrix.\n",
        "\n",
        "  Args:\n",
        "    cm (array, shape = [n, n]): a confusion matrix of integer classes\n",
        "    class_names (array, shape = [n]): String names of the integer classes\n",
        "  \"\"\"\n",
        "  figure = plt.figure(figsize=(8, 8))\n",
        "  plt.imshow(cm, interpolation='nearest', cmap=plt.cm.Blues)\n",
        "  plt.title(\"Confusion matrix\")\n",
        "  plt.colorbar()\n",
        "  tick_marks = np.arange(len(class_names))\n",
        "  plt.xticks(tick_marks, class_names, rotation=45)\n",
        "  plt.yticks(tick_marks, class_names)\n",
        "\n",
        "  # Normalize the confusion matrix.\n",
        "  cm = np.around(cm.astype('float') / cm.sum(axis=1)[:, np.newaxis], decimals=2)\n",
        "\n",
        "  # Use white text if squares are dark; otherwise black.\n",
        "  threshold = cm.max() / 2.\n",
        "  for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
        "    color = \"white\" if cm[i, j] > threshold else \"black\"\n",
        "    plt.text(j, i, cm[i, j], horizontalalignment=\"center\", color=color)\n",
        "\n",
        "  plt.tight_layout()\n",
        "  plt.ylabel('True label')\n",
        "  plt.xlabel('Predicted label')\n",
        "  return figure"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "doAndoDqgG9W"
      },
      "source": [
        "\n",
        "def log_confusion_matrix(epoch, logs):\n",
        "  # Use the model to predict the values from the validation dataset.\n",
        "  test_pred_raw = model.predict(im)\n",
        "  test_pred = np.argmax(test_pred_raw, axis=1)\n",
        "\n",
        "      # Calculate the confusion matrix.\n",
        "  cm = sklearn.metrics.confusion_matrix(l, test_pred)\n",
        "  # Log the confusion matrix as an image summary.\n",
        "  figure = plot_confusion_matrix(cm, class_names=class_names)\n",
        "  cm_image = plot_to_image(figure)\n",
        "\n",
        "  # Log the confusion matrix as an image summary.\n",
        "  with file_writer_cm.as_default():\n",
        "    tf.summary.image(\"Confusion Matrix\", cm_image, step=epoch)\n",
        "\n",
        "# Define the per-epoch callback.\n",
        "cm_callback = tf.keras.callbacks.LambdaCallback(on_epoch_end=log_confusion_matrix)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F5u5UnDu1Vrr"
      },
      "source": [
        "!pip install scikit-plot"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Zghw7sULNzgh"
      },
      "source": [
        "import scikitplot as skplt\n",
        "\n",
        "def plot_roc(y_true, y_probas):\n",
        "  #figure = plt.figure(figsize=(8, 8))\n",
        "  figure, axes = plt.subplots(1,1, figsize = (8,8))\n",
        "\n",
        "  skplt.metrics.plot_roc_curve(y_true, y_probas , ax =axes ,text_fontsize ='small', figsize= (8 ,8))\n",
        "  plt.title('ROC')\n",
        "  #plt.colorbar()\n",
        "  plt.ylabel('True Label')\n",
        "  plt.xlabel('Predicated Label')\n",
        "  fig = plt.gcf()\n",
        "  #plt.show()\n",
        "  fig.savefig(\"test_rasterization.png\", dpi=150)\n",
        "  #print(fig)\n",
        "  \n",
        "\n",
        "  return fig"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lBGmesCQIfEX"
      },
      "source": [
        "def log_roc(epoch, logs):\n",
        "  test_pred_raw = model.predict(im)\n",
        "  test_pred = np.argmax(test_pred_raw, axis=1)\n",
        "  #print(test_pred.shape)\n",
        "  #print(l.shape)\n",
        "  figure_roc = plot_roc(l, test_pred_raw)\n",
        "  roc_image = plot_to_image(figure_roc)\n",
        "\n",
        "\n",
        "  # Log the roc  as an image summary.\n",
        "  with file_writer_roc.as_default():\n",
        "    tf.summary.image(\"ROC\", roc_image, step=epoch)\n",
        "\n",
        "roc_callback = tf.keras.callbacks.LambdaCallback( on_epoch_end=log_roc)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f7g0RRJlR4Db"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B8DekOScSMUS"
      },
      "source": [
        "cc"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "O5o-gfVAR2SK"
      },
      "source": [
        "\n",
        "\n",
        "```\n",
        "# learning rate dense nodes accuacy \n",
        "#  0.0002           101      16%\n",
        "#  0.002            1280     15%\n",
        "```\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w_YKX2Qnfg6x"
      },
      "source": [
        "EPOCHS = 40\n",
        "# Start TensorBoard.\n",
        "\n",
        "\n",
        "#%tensorboard --logdir logs/\n",
        "\n",
        "\n",
        "\n",
        "hist = model.fit(train_batches,\n",
        "                 epochs=EPOCHS,\n",
        "                 callbacks =[early_stop_callback, reduce_lr],\n",
        "                 validation_data=validation_batches,\n",
        "                 validation_steps = 10)\n",
        "                 #callbacks=[tensorboard_callback])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0KT52QnA2X-d"
      },
      "source": [
        "from matplotlib import pyplot as plt\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "fig, axs = plt.subplots(2, 1 , figsize=(10,5))\n",
        "#axs[0, 0].plot(x, y)\n",
        "##axs[0, 0].set_title('Axis [0, 0]')\n",
        "#axs[0, 1].plot(x, y, 'tab:orange')\n",
        "#axs[0, 1].set_title('Axis [0, 1]')\n",
        "#axs[1, 0].plot(x, -y, 'tab:green')\n",
        "#axs[1, 0].set_title('Axis [1, 0]')\n",
        "#axs[1, 1].plot(x, -y, 'tab:red')\n",
        "#axs[1, 1].set_title('Axis [1, 1]')\n",
        "\n",
        "\n",
        "\n",
        "#plt.yscale('log')\n",
        "axs[0].plot(hist.history['loss'])\n",
        "axs[0].plot(hist.history['val_loss'])\n",
        "axs[1].plot(hist.history['accuracy'])\n",
        "axs[1].plot(hist.history['val_accuracy'])\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S88WGzO3Wkbv"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t1ZPPJWCCQDf"
      },
      "source": [
        "model.evaluate(test_batches.take(150000))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qc7afD3z8ePi"
      },
      "source": [
        "model.evaluate(validation_batches.take(10000))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O3kv7nGT-KK5"
      },
      "source": [
        "predictions = []\n",
        "real_label  = []\n",
        "for image_batch , labels_batch in validation_batches.take(99):\n",
        "  \n",
        "  predictions.extend(np.argmax(model.predict(image_batch), axis =-1))\n",
        "  real_label.extend(labels_batch.numpy())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Yi7CRXIQ-c4G"
      },
      "source": [
        "import seaborn as sns\n",
        "import pandas as pd\n",
        "from sklearn.metrics import classification_report\n",
        "plt.figure(figsize = (7,30))\n",
        "#print(\"the classification report : \\n\" , cl_report)\n",
        "cl_report = classification_report(real_label,predictions, target_names = class_names, output_dict=True)\n",
        "sns.heatmap(pd.DataFrame(cl_report).iloc[:-1, :].T, annot= True, linewidths=.5)\n",
        "#print(list(val_ds.class_names))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MqDgLfSn_otc"
      },
      "source": [
        "import sklearn as sklearn\n",
        "from sklearn.metrics import confusion_matrix\n",
        "\n",
        "\n",
        "\n",
        "cm = confusion_matrix(real_label, predictions)\n",
        "print(cm)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZUsknYee_q4T"
      },
      "source": [
        "import numpy as np\n",
        "\n",
        "\n",
        "def plot_confusion_matrix(cm,\n",
        "                          target_names,\n",
        "                          title='Confusion matrix',\n",
        "                          cmap=None,\n",
        "                          normalize=True):\n",
        "    \"\"\"\n",
        "    given a sklearn confusion matrix (cm), make a nice plot\n",
        "\n",
        "    Arguments\n",
        "    ---------\n",
        "    cm:           confusion matrix from sklearn.metrics.confusion_matrix\n",
        "\n",
        "    target_names: given classification classes such as [0, 1, 2]\n",
        "                  the class names, for example: ['high', 'medium', 'low']\n",
        "\n",
        "    title:        the text to display at the top of the matrix\n",
        "\n",
        "    cmap:         the gradient of the values displayed from matplotlib.pyplot.cm\n",
        "                  see http://matplotlib.org/examples/color/colormaps_reference.html\n",
        "                  plt.get_cmap('jet') or plt.cm.Blues\n",
        "\n",
        "    normalize:    If False, plot the raw numbers\n",
        "                  If True, plot the proportions\n",
        "\n",
        "    Usage\n",
        "    -----\n",
        "    plot_confusion_matrix(cm           = cm,                  # confusion matrix created by\n",
        "                                                              # sklearn.metrics.confusion_matrix\n",
        "                          normalize    = True,                # show proportions\n",
        "                          target_names = y_labels_vals,       # list of names of the classes\n",
        "                          title        = best_estimator_name) # title of graph\n",
        "\n",
        "    Citiation\n",
        "    ---------\n",
        "    http://scikit-learn.org/stable/auto_examples/model_selection/plot_confusion_matrix.html\n",
        "\n",
        "    \"\"\"\n",
        "    import matplotlib.pyplot as plt\n",
        "    import numpy as np\n",
        "    import itertools\n",
        "\n",
        "    accuracy = np.trace(cm) / np.sum(cm).astype('float')\n",
        "    misclass = 1 - accuracy\n",
        "\n",
        "    if cmap is None:\n",
        "        cmap = plt.get_cmap('Blues')\n",
        "\n",
        "    plt.figure(figsize=(40, 40))\n",
        "    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n",
        "    plt.title(title)\n",
        "    #plt.colorbar()\n",
        "\n",
        "    if target_names is not None:\n",
        "        tick_marks = np.arange(len(target_names))\n",
        "        plt.xticks(tick_marks, target_names, rotation=90)\n",
        "        plt.yticks(tick_marks, target_names)\n",
        "\n",
        "    if normalize:\n",
        "        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
        "\n",
        "\n",
        "    thresh = cm.max() / 1.5 if normalize else cm.max() / 2\n",
        "    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
        "        if normalize:\n",
        "            plt.text(j, i, \"{:0.4f}\".format(cm[i, j]),\n",
        "                     horizontalalignment=\"center\",\n",
        "                     color=\"white\" if cm[i, j] > thresh else \"black\")\n",
        "        else:\n",
        "            plt.text(j, i, \"{:,}\".format(cm[i, j]),\n",
        "                     horizontalalignment=\"center\",\n",
        "                     color=\"white\" if cm[i, j] > thresh else \"black\")\n",
        "\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.ylabel('True label')\n",
        "    plt.xlabel('Predicted label\\naccuracy={:0.4f}; misclass={:0.4f}'.format(accuracy, misclass))\n",
        "    plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EQOpnQj1_u7e"
      },
      "source": [
        "plot_confusion_matrix(cm = cm,\n",
        "                          target_names= class_names,\n",
        "                          title='Confusion matrix',\n",
        "                          cmap='inferno_r',\n",
        "                          normalize=False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bvMaSP8QuZ2Z"
      },
      "source": [
        "CLS = class_names"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v7L1k6IsBDWS"
      },
      "source": [
        "\n",
        "\n",
        "def plot_image(i, predictions_array, true_label, img):\n",
        "  predictions_array, true_label, img = predictions_array, true_label[i], img[i]\n",
        "  plt.grid(False)\n",
        "  plt.xticks([])\n",
        "  plt.yticks([])\n",
        "\n",
        "  plt.imshow(img.numpy().astype(\"uint8\"))\n",
        "\n",
        "  predicted_label = np.argmax(predictions_array)\n",
        "  #print(predicted_label)\n",
        "  if predicted_label == true_label:\n",
        "    color = 'blue'\n",
        "  else:\n",
        "    color = 'red'\n",
        "\n",
        "  plt.xlabel(\"{} {:2.0f}% ({})\".format(CLS[predicted_label],\n",
        "                                100*np.max(predictions_array),\n",
        "                                CLS[true_label]),\n",
        "                                color=color)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "def plot_value_array(i, predictions_array, true_label):\n",
        "  predictions_array, true_label = predictions_array, true_label[i]\n",
        "  plt.grid(False)\n",
        "  plt.xticks(range(101) , rotation =90)\n",
        "  plt.yticks([])\n",
        "  thisplot = plt.bar(range(101), predictions_array, color=\"#777777\")\n",
        "  plt.ylim([0, 1])\n",
        "  predicted_label = np.argmax(predictions_array)\n",
        "  #print(predicted_label)\n",
        "  #print(true_label)\n",
        "  thisplot[predicted_label].set_color('red')\n",
        "  thisplot[true_label].set_color('blue')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hARdxjGtBN4J"
      },
      "source": [
        "\n",
        "\n",
        "for imgs , lbs in test_batches.take(2):\n",
        "  \n",
        "  pred = model.predict(imgs)\n",
        "  "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iFlLODhxCq7L"
      },
      "source": [
        "\n",
        "i = 0\n",
        "plt.figure(figsize=(60,3))\n",
        "plt.subplot(1,2,1)\n",
        "\n",
        "\n",
        "\n",
        "plot_image(i, pred[i], lbs, imgs)\n",
        "plt.subplot(1,2,2)\n",
        "plot_value_array(i, pred[i],  lbs)\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8fAb75sCCe-m"
      },
      "source": [
        "print(pred.shape)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZDWvzLXPuEzO"
      },
      "source": [
        "cm_test_batches = test_examples.batch(240).map(format_image)\n",
        "\n",
        "b,  = cm_test_batches.take(1)\n",
        "test_im , test_l = b[0], b[1]\n",
        "\n",
        "print(test_im.shape)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HAPzI7T8u5oY"
      },
      "source": [
        "test_pred_raw = model.predict(test_im)\n",
        "test_pred = np.argmax(test_pred_raw, axis=1)\n",
        "print(\"true label:\" , len(test_l.numpy()))\n",
        "print(\"predicted label:\" , len(test_pred))\n",
        "cl_report = sklearn.metrics.classification_report(test_l.numpy(), test_pred, target_names = class_names)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NbnNFHGtuH9U"
      },
      "source": [
        "print(\"the classification report : \\n\" , cl_report)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0BTcqoT_viwg"
      },
      "source": [
        "skplt.metrics.plot_roc_curve(test_l, test_pred_raw ,text_fontsize ='small', figsize= (8 ,8))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "u_psFoTeLpHU"
      },
      "source": [
        "## Export the Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XaSb5nVzHcVv"
      },
      "source": [
        "RPS_SAVED_MODEL = \"rps_saved_model\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fZqRAg1uz1Nu"
      },
      "source": [
        "Export the SavedModel"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yJMue5YgnwtN"
      },
      "source": [
        "tf.saved_model.save(model, RPS_SAVED_MODEL)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SOQF4cOan0SY"
      },
      "source": [
        "%%bash -s $RPS_SAVED_MODEL\n",
        "saved_model_cli show --dir $1 --tag_set serve --signature_def serving_default"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FY7QGBgBytwX"
      },
      "source": [
        "loaded = tf.saved_model.load(RPS_SAVED_MODEL)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tIhPyMISz952"
      },
      "source": [
        "print(list(loaded.signatures.keys()))\n",
        "infer = loaded.signatures[\"serving_default\"]\n",
        "print(infer.structured_input_signature)\n",
        "print(infer.structured_outputs)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XxLiLC8n0H16"
      },
      "source": [
        "## Convert Using TFLite's Converter"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WmSr2-yZoUhz"
      },
      "source": [
        "converter = tf.lite.TFLiteConverter.from_saved_model(RPS_SAVED_MODEL)\n",
        "converter.optimizations = [tf.lite.Optimize.OPTIMIZE_FOR_SIZE]\n",
        "tflite_model = converter.convert()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZB8jxCwQKS-h"
      },
      "source": [
        "tflite_model_file = 'converted_model.tflite'\n",
        "\n",
        "with open(tflite_model_file, \"wb\") as f:\n",
        "    f.write(tflite_model)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BbTF6nd1KG2o"
      },
      "source": [
        "## Test the TFLite Model Using the Python Interpreter"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dg2NkVTmLUdJ"
      },
      "source": [
        "# Load TFLite model and allocate tensors.\n",
        "with open(tflite_model_file, 'rb') as fid:\n",
        "    tflite_model = fid.read()\n",
        "    \n",
        "interpreter = tf.lite.Interpreter(model_content=tflite_model)\n",
        "interpreter.allocate_tensors()\n",
        "\n",
        "input_index = interpreter.get_input_details()[0][\"index\"]\n",
        "output_index = interpreter.get_output_details()[0][\"index\"]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "snJQVs9JNglv"
      },
      "source": [
        "# Gather results for the randomly sampled test images\n",
        "predictions = []\n",
        "\n",
        "test_labels, test_imgs = [], []\n",
        "for img, label in tqdm(test_batches.take(100)):\n",
        "    interpreter.set_tensor(input_index, img)\n",
        "    interpreter.invoke()\n",
        "    predictions.append(interpreter.get_tensor(output_index))\n",
        "    \n",
        "    test_labels.append(label.numpy()[0])\n",
        "    test_imgs.append(img)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YMTWNqPpNiAI"
      },
      "source": [
        "#@title Utility functions for plotting\n",
        "# Utilities for plotting\n",
        "\n",
        "#class_names = ['dandelion',\n",
        "#'daisy',\n",
        "#'tulips',\n",
        "#'sunflowers',\n",
        "#'roses']\n",
        "\n",
        "def plot_image(i, predictions_array, true_label, img):\n",
        "    predictions_array, true_label, img = predictions_array[i], true_label[i], img[i]\n",
        "    plt.grid(False)\n",
        "    plt.xticks([])\n",
        "    plt.yticks([])\n",
        "    \n",
        "    img = np.squeeze(img)\n",
        "    \n",
        "    plt.imshow(img[: , : , 0], cmap=plt.cm.binary)\n",
        "    \n",
        "    predicted_label = np.argmax(predictions_array)\n",
        "    \n",
        "    print(type(predicted_label), type(true_label))\n",
        "    \n",
        "    if predicted_label == true_label:\n",
        "        color = 'green'\n",
        "    else:\n",
        "        color = 'red'\n",
        "        \n",
        "    plt.xlabel(\"{} {:2.0f}% ({})\".format(class_names[predicted_label],\n",
        "                                         100*np.max(predictions_array),\n",
        "                                         class_names[true_label]), color=color)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1-lbnicPNkZs"
      },
      "source": [
        "#@title Visualize the outputs { run: \"auto\" }\n",
        "index = 81 #@param {type:\"slider\", min:0, max:100, step:1}\n",
        "plt.figure(figsize=(8,8))\n",
        "plt.subplot(1,2,1)\n",
        "plot_image(index, predictions, test_labels, test_imgs)\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "s4IRRdmIKS_H"
      },
      "source": [
        "Create a file to save the labels."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3Yo7InJXKS_H"
      },
      "source": [
        "with open('labels.txt', 'w') as f:\n",
        "    f.write('\\n'.join(class_names))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PmZRieHmKLY5"
      },
      "source": [
        "If you are running this notebook in a Colab, you can run the cell below to download the model and labels to your local disk.\n",
        "\n",
        "**Note**: If the files do not download when you run the cell, try running the cell a second time. Your browser might prompt you to allow multiple files to be downloaded. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0jJAxrQB2VFw"
      },
      "source": [
        "try:\n",
        "    from google.colab import files\n",
        "    files.download('converted_model.tflite')\n",
        "    files.download('labels.txt')\n",
        "except:\n",
        "    pass"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BDlmpjC6VnFZ"
      },
      "source": [
        "# Prepare the Test Images for Download (Optional)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_1ja_WA0WZOH"
      },
      "source": [
        "This part involves downloading additional test images for the Mobile Apps only in case you need to try out more samples"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fzLKEBrfTREA"
      },
      "source": [
        "!mkdir -p test_images"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Qn7ukNQCSewb"
      },
      "source": [
        "from PIL import Image\n",
        "\n",
        "for index, (image, label) in enumerate(test_batches.take(50)):\n",
        "    image = tf.cast(image * 255.0, tf.uint8)\n",
        "    image = tf.squeeze(image).numpy()\n",
        "    pil_image = Image.fromarray(image)\n",
        "    pil_image.save('test_images/{}_{}.jpg'.format(class_names[label[0]], index))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xVKKWUG8UMO5"
      },
      "source": [
        "!ls test_images"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l_w_-UdlS9Vi"
      },
      "source": [
        "!zip -qq rps_test_images.zip -r test_images/"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RxGDmWWxKS_f"
      },
      "source": [
        "If you are running this notebook in a Colab, you can run the cell below to download the Zip file with the images to your local disk. \n",
        "\n",
        "**Note**: If the Zip file does not download when you run the cell, try running the cell a second time."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Giva6EHwWm6Y"
      },
      "source": [
        "try:\n",
        "    files.download('rps_test_images.zip')\n",
        "except:\n",
        "    pass"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D2-HUjtoofcG"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}